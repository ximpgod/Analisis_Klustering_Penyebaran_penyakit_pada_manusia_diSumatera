# ğŸ¥ Clustering Penyakit Sumatera Utara

Pipeline big data untuk clustering kasus penyakit di Sumatera Utara menggunakan Apache Spark dan Machine Learning. Proyek ini mengimplementasikan end-to-end pipeline untuk analisis dan visualisasi pola penyakit di kabupaten/kota di Sumatera Utara.

## ğŸ¯ Tujuan Proyek

Mengembangkan sistem clustering untuk:
- ğŸ“Š Mengelompokkan kabupaten/kota berdasarkan kemiripan pola penyakit
- ğŸ¯ Mengidentifikasi wilayah dengan beban penyakit tinggi
- ğŸ“ˆ Memberikan insights untuk alokasi sumber daya kesehatan
- ğŸ—ºï¸ Menyediakan visualisasi untuk decision makers

## ğŸ—ï¸ Arsitektur Sistem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Source   â”‚â”€â”€â”€â–¶â”‚  Apache Spark   â”‚â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚
â”‚ Penyakit_Sumut  â”‚    â”‚  ETL Pipeline   â”‚    â”‚  Data Warehouse â”‚
â”‚      .csv       â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Spark MLlib   â”‚    â”‚   Visualization â”‚
                       â”‚ KMeans Clusteringâ”‚    â”‚ Jupyter/Tableau â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dataset

**Sumber**: Dinas Kesehatan Sumatera Utara (2024)
**Coverage**: 34 Kabupaten/Kota di Sumatera Utara

### Jenis Penyakit yang Dianalisis:
- ğŸ¦  AIDS (Kasus Baru & Kumulatif)
- ğŸ”´ DBD (Demam Berdarah Dengue)
- ğŸ’§ Diare
- ğŸ« TB Paru (Tuberkulosis)
- ğŸ‘¶ Pneumonia Balita
- ğŸ¤’ Campak (Suspek)
- ğŸ¦Ÿ Malaria (Suspek)
- ğŸ¤² Kusta
- ğŸ§¬ HIV (Kasus Baru & Kumulatif)
- ğŸ’‰ Tetanus

## ğŸš€ Quick Start

### Prerequisites
- Docker dan Docker Compose
- Minimum 8GB RAM
- 10GB free disk space

### 1. Clone & Setup
```bash
git clone <repository>
cd ABD
```

### 2. Siapkan Data
Letakkan file `Penyakit_Sumut.csv` di folder `data/`:
```
data/
â””â”€â”€ Penyakit_Sumut.csv
```

### 3. Jalankan Pipeline
```bash
# Start semua services
docker-compose up -d

# Tunggu services ready, lalu jalankan pipeline
docker-compose exec spark-master bash /scripts/run_pipeline.sh
```

### 4. Akses Results
- ğŸ““ **Jupyter Notebook**: http://localhost:8888 (token: `penyakit123`)
- ğŸ—„ï¸ **pgAdmin**: http://localhost:5050 (admin@admin.com / admin123)
- ğŸ“ˆ **Spark UI**: http://localhost:8080

## ğŸ“‚ Struktur Proyek

```
project_root/
â”œâ”€â”€ ğŸ³ docker-compose.yml          # Orchestration services
â”œâ”€â”€ ğŸ“Š data/
â”‚   â”œâ”€â”€ Penyakit_Sumut.csv         # Source data
â”‚   â”œâ”€â”€ output/                    # Hasil clustering & visualisasi
â”‚   â””â”€â”€ parquet/                   # Intermediate data storage
â”œâ”€â”€ ğŸ”§ scripts/
â”‚   â”œâ”€â”€ ingest_data.sh             # Data ingestion
â”‚   â”œâ”€â”€ etl_transform.sh           # Data transformation
â”‚   â”œâ”€â”€ run_clustering.sh          # ML clustering
â”‚   â”œâ”€â”€ export_results.sh          # Export untuk visualisasi
â”‚   â””â”€â”€ run_pipeline.sh            # Master pipeline script
â”œâ”€â”€ ğŸ’» src/
â”‚   â”œâ”€â”€ ingest_data.py             # PySpark data ingestion
â”‚   â”œâ”€â”€ etl_transform.py           # PySpark transformations
â”‚   â”œâ”€â”€ run_clustering.py          # Spark MLlib clustering
â”‚   â””â”€â”€ export_results.py          # Results export
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ exploratory_analysis.ipynb # Jupyter analysis
â”œâ”€â”€ ğŸ—„ï¸ sql/
â”‚   â””â”€â”€ schema_postgres.sql        # Database schema
â””â”€â”€ ğŸ“– README.md
```

## ğŸ”„ Pipeline Stages

### Stage 1: Data Ingestion ğŸ“¥
- Membaca CSV menggunakan PySpark
- Validasi dan cleaning data
- Insert data kabupaten ke PostgreSQL
- Save ke Parquet format

### Stage 2: ETL Transform ğŸ”„
- Handle missing values
- Data normalization (opsional)
- Save processed data ke PostgreSQL
- Prepare features untuk clustering

### Stage 3: Clustering Analysis ğŸ§ 
- Feature engineering dengan VectorAssembler
- Standardization dengan StandardScaler
- KMeans clustering (K=4)
- Model evaluation dengan Silhouette Score
- Save results ke PostgreSQL

### Stage 4: Export Results ğŸ“¤
- Generate summary statistics
- Export ke CSV untuk Tableau
- Create comprehensive reports
- Generate basic visualizations

## ğŸ¯ Hasil Clustering

### Cluster Characteristics:
- **Cluster 0**: Wilayah dengan beban penyakit rendah
- **Cluster 1**: Wilayah dengan fokus penyakit menular
- **Cluster 2**: Wilayah dengan beban penyakit sedang
- **Cluster 3**: Wilayah dengan beban penyakit tinggi

### Output Files:
```
data/output/
â”œâ”€â”€ ğŸ“Š tableau_export.csv              # Ready untuk Tableau
â”œâ”€â”€ ğŸ“ˆ cluster_summary_stats.csv       # Statistik per cluster
â”œâ”€â”€ ğŸ“‹ clustering_summary_report.txt   # Laporan komprehensif
â”œâ”€â”€ ğŸ’¾ clustering_results_detailed.csv # Detail hasil clustering
â””â”€â”€ ğŸ“Š analysis_summary.json           # Summary untuk API
```

## ğŸ“Š Visualisasi

### Jupyter Notebook
- Interactive analysis dengan Plotly
- Statistical summaries
- Cluster characteristics analysis
- Heatmaps dan scatter plots

### Tableau Dashboard
Gunakan `tableau_export.csv` untuk membuat:
- ğŸ—ºï¸ Choropleth maps wilayah clusters
- ğŸ“Š Bar charts disease burden
- ğŸ“ˆ Time series analysis (jika ada data temporal)
- ğŸ¯ Interactive filters per penyakit

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Orchestration** | Docker Compose | Service management |
| **Big Data Processing** | Apache Spark 3.4 | ETL & ML pipeline |
| **Machine Learning** | Spark MLlib | KMeans clustering |
| **Data Warehouse** | PostgreSQL 15 | Structured data storage |
| **Analytics** | Jupyter Lab | Interactive analysis |
| **Visualization** | Tableau/Plotly | Dashboard & charts |
| **Admin** | pgAdmin 4 | Database management |

## ğŸ”§ Configuration

### Environment Variables
```bash
# Database
POSTGRES_HOST=postgres
POSTGRES_DB=penyakit_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password123

# Spark
SPARK_MASTER_URL=spark://spark-master:7077

# Jupyter
JUPYTER_TOKEN=penyakit123
```

### Spark Configuration
- Driver Memory: 1GB
- Executor Memory: 1GB
- Total Executor Cores: 2

## ğŸ“‹ API Reference

### PostgreSQL Tables

#### `hasil_klaster`
```sql
SELECT kabupaten, cluster_id FROM hasil_klaster;
```

#### `data_pivot`
```sql
SELECT kabupaten, dbd, diare, tb_paru, aids_kasus_baru 
FROM data_pivot ORDER BY cluster_id;
```

### Key Metrics
- **Silhouette Score**: Model evaluation metric
- **WSSSE**: Within Set Sum of Squared Errors
- **Cluster Distribution**: Jumlah kabupaten per cluster

## ğŸ§ª Testing & Validation

### Data Quality Checks
- âœ… No missing kabupaten names
- âœ… Numeric values validation
- âœ… Outlier detection
- âœ… Cluster balance check

### Model Validation
- âœ… Silhouette Score > 0.3
- âœ… Reasonable cluster sizes
- âœ… Geographic distribution makes sense

## ğŸš€ Deployment

### Production Considerations
1. **Scaling**: Increase Spark executors untuk dataset besar
2. **Security**: Ganti default passwords
3. **Monitoring**: Add logging & alerting
4. **Backup**: Regular PostgreSQL backup strategy

### Docker Resources
```yaml
# Minimum requirements
spark-master:
  mem_limit: 2g
spark-worker:
  mem_limit: 2g
postgres:
  mem_limit: 1g
```

## ğŸ› Troubleshooting

### Common Issues

**Service tidak start**
```bash
# Check logs
docker-compose logs [service-name]

# Restart services
docker-compose restart
```

**Pipeline gagal**
```bash
# Check individual scripts
docker-compose exec spark-master bash /scripts/ingest_data.sh
```

**Data tidak muncul**
```bash
# Check PostgreSQL connection
docker-compose exec postgres psql -U postgres -d penyakit_db -c "\dt"
```

## ğŸ“š References

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Spark MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Docker Compose Reference](https://docs.docker.com/compose/)

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

## ğŸ‘¥ Team

**Data Engineering Team - Institut Teknologi Sumatera**
- ğŸ“§ Contact: dataeng@itera.ac.id
- ğŸŒ Website: https://itera.ac.id

---

**ğŸ¯ Untuk memulai analisis clustering penyakit Sumatera Utara, jalankan pipeline dan akses Jupyter Notebook untuk eksplorasi data yang komprehensif!**
